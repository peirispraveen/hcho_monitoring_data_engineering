{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"HCHO_Analysis\").getOrCreate()\n",
    "\n",
    "# Load data into Spark DataFrames\n",
    "col_mat_nuw = spark.read.csv(\"col_mat_nuw_output.csv\", header=True, inferSchema=True)\n",
    "mon_kur_jaf = spark.read.csv(\"mon_kur_jaf_output.csv\", header=True, inferSchema=True)\n",
    "kan = spark.read.csv(\"kan_output.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Combine DataFrames\n",
    "data = col_mat_nuw.union(mon_kur_jaf).union(kan)\n",
    "\n",
    "# Data Preprocessing\n",
    "cleaned_data = data.dropna(subset=[\"HCHO reading\"]) \\\n",
    "                    .withColumn(\"HCHO reading\", col(\"HCHO reading\").cast(T.DoubleType())) \\\n",
    "                    .filter((col(\"HCHO reading\") >= quantile_approx(\"HCHO reading\", 0.25, [0.5]) - 1.5 * qr) &\n",
    "                            (col(\"HCHO reading\") <= quantile_approx(\"HCHO reading\", 0.75, [0.5]) + 1.5 * qr))\n",
    "\n",
    "# Descriptive statistics\n",
    "summary_stats = cleaned_data.groupBy(\"Location\").agg(\n",
    "    avg(\"HCHO reading\").alias(\"mean\"),\n",
    "    stddev(\"HCHO reading\").alias(\"std_dev\"),\n",
    "    approx_count_distinct(\"HCHO reading\").alias(\"count\")\n",
    ")\n",
    "summary_stats.show()\n",
    "\n",
    "# Visualize data distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pdf = cleaned_data.select(\"HCHO reading\", \"Location\").toPandas()\n",
    "sns.histplot(data=pdf, x=\"HCHO reading\", hue=\"Location\", kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Spatio-Temporal Analysis\n",
    "# ...\n",
    "\n",
    "# Machine Learning\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Temperature\", \"Precipitation\", ...], outputCol=\"features\")\n",
    "data_ml = assembler.transform(merged_data)\n",
    "\n",
    "train_data, test_data = data_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "gbt = GBTRegressor(labelCol=\"HCHO reading\", featuresCol=\"features\")\n",
    "model = gbt.fit(train_data)\n",
    "\n",
    "# Evaluate model performance\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = RegressionEvaluator(labelCol=\"HCHO reading\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "\n",
    "# Communication and Insights\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
